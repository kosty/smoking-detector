{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Overfit single batch",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "RM2WYeMhzVms",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# root_path = Path('gdrive/My Drive/ADL/handcrafted_dataset/')\n",
        "# for i in root_path.iterdir():\n",
        "# classes = ['smoking','not_smoking']\n",
        "# print(classes)\n",
        "\n",
        "epochs = 10\n",
        "batch_size = 32\n",
        "data_root = Path('gdrive/My Drive/ADL/handcrafted_dataset/')\n",
        "all_image_paths, label_names = dir_to_paths_and_labels(data_root)\n",
        "a_batch = unbatched_dataset(all_image_paths, label_names, verbose=True)\n",
        "a_batch = a_batch.batch(batch_size)\n",
        "a_batch = a_batch.repeat(epochs)\n",
        "\n",
        "\n",
        "def to_naive(x, y):\n",
        "  return tf.reshape(x, shape=(-1, 12288)), y\n",
        "\n",
        "a_batch = a_batch.map(to_naive)\n",
        "\n",
        "b_iter = iter(a_batch)\n",
        "overfit_batch = next(b_iter)\n",
        "validate_batch = next(b_iter)\n",
        "\n",
        "print(overfit_batch[0])\n",
        "print(overfit_batch[1])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkfGTVA7B0Z8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import Image\n",
        "try:\n",
        "  filename = take_photo()\n",
        "  print('Saved to {}'.format(filename))\n",
        "  \n",
        "  # Show the image which was just taken.\n",
        "  display(Image(filename))\n",
        "except Exception as err:\n",
        "  # Errors will be thrown if the user does not have a webcam or if they do not\n",
        "  # grant the page permission to access it.\n",
        "  print(str(err))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnGqwfwR5BN0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
        "from pathlib import Path\n",
        "\n",
        "pre = Path('gdrive/My Drive/ADL')\n",
        "handcrafted_root = pre/'handcrafted_dataset'\n",
        "collected_root = pre/'dataset'\n",
        "\n",
        "data_generator = ImageDataGenerator(horizontal_flip=True,\n",
        "                                   width_shift_range = 0.4,\n",
        "                                   height_shift_range = 0.4,\n",
        "                                   zoom_range=0.3,\n",
        "                                   rotation_range=20,\n",
        "                                   )\n",
        "\n",
        "image_size = 64\n",
        "batch_size = 32"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U42BneuG4N5N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "handcrafted_generator = data_generator.flow_from_directory(\n",
        "        handcrafted_root,\n",
        "        target_size=(image_size, image_size),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')\n",
        "\n",
        "generator = handcrafted_generator\n",
        "num_classes = len(generator.class_indices)\n",
        "\n",
        "dataset_iter = iter(generator)\n",
        "single_batch = next(dataset_iter)\n",
        "valida_batch = next(dataset_iter)\n",
        "\n",
        "# sb = next(iter(train_generator))\n",
        "# print(sb[0].reshape((-1, 64*64*3)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O36GeZFS4XUE",
        "colab_type": "code",
        "outputId": "3287c6c2-4c64-4238-ddaf-ec7b229cd75e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "train_generator = data_generator.flow_from_directory(\n",
        "        collected_root/'train',\n",
        "        target_size=(image_size, image_size),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')\n",
        "\n",
        "valid_generator = data_generator.flow_from_directory(\n",
        "        collected_root/'validation',\n",
        "        target_size=(image_size, image_size),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')\n",
        "\n",
        "generator = train_generator\n",
        "num_classes = len(generator.class_indices)\n",
        "\n",
        "dataset_iter = iter(generator)\n",
        "single_batch = next(dataset_iter)\n",
        "valida_batch = next(dataset_iter)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 8244 images belonging to 2 classes.\n",
            "Found 1033 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3elvZ_UXQHp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import backend as K\n",
        "K.tensorflow_backend._get_available_gpus()\n",
        "\n",
        "model = resnet50_model()\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['binary_accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
        "\n",
        "# model = naive_model(hidden=128)\n",
        "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy']) \n",
        "\n",
        "# single_batch = next(iter(train_generator))\n",
        "# model.fit(single_batch[0].reshape(-1, (image_size*image_size*3)), single_batch[1], steps_per_epoch=5, epochs=30)\n",
        "# int(count/batch_size) + 1,\n",
        "#        batch_size=batch_size,"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfj_wLT30GUx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(\n",
        "    single_batch[0],\n",
        "    single_batch[1],\n",
        "    steps_per_epoch=5,\n",
        "    validation_data=valida_batch,\n",
        "    validation_steps=1,\n",
        "    verbose = 1,\n",
        "    epochs=60)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pzN-j-y7VBF",
        "colab_type": "code",
        "outputId": "f5b76321-6680-4c15-88f9-2c3fb4f56436",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3180
        }
      },
      "source": [
        "model.fit_generator(\n",
        "    train_generator,\n",
        "    validation_data=valida_batch,\n",
        "    validation_steps=1,\n",
        "    verbose = 1,\n",
        "    epochs=60)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "32/32 [==============================] - 0s 2ms/sample - loss: 0.4953 - binary_accuracy: 0.8438 - precision_1: 0.8438 - recall_1: 0.8438\n",
            "258/258 [==============================] - 2676s 10s/step - loss: 0.9233 - binary_accuracy: 0.6452 - precision_1: 0.6452 - recall_1: 0.6452 - val_loss: 0.4953 - val_binary_accuracy: 0.8438 - val_precision_1: 0.8438 - val_recall_1: 0.8438\n",
            "Epoch 2/60\n",
            "32/32 [==============================] - 0s 1ms/sample - loss: 0.5296 - binary_accuracy: 0.7188 - precision_1: 0.7188 - recall_1: 0.7188\n",
            "258/258 [==============================] - 49s 190ms/step - loss: 0.5983 - binary_accuracy: 0.6886 - precision_1: 0.6886 - recall_1: 0.6886 - val_loss: 0.5296 - val_binary_accuracy: 0.7188 - val_precision_1: 0.7188 - val_recall_1: 0.7188\n",
            "Epoch 3/60\n",
            "32/32 [==============================] - 0s 2ms/sample - loss: 0.4982 - binary_accuracy: 0.7500 - precision_1: 0.7500 - recall_1: 0.7500\n",
            "258/258 [==============================] - 49s 189ms/step - loss: 0.5937 - binary_accuracy: 0.6919 - precision_1: 0.6919 - recall_1: 0.6919 - val_loss: 0.4982 - val_binary_accuracy: 0.7500 - val_precision_1: 0.7500 - val_recall_1: 0.7500\n",
            "Epoch 4/60\n",
            "32/32 [==============================] - 0s 1ms/sample - loss: 0.5118 - binary_accuracy: 0.7188 - precision_1: 0.7188 - recall_1: 0.7188\n",
            "258/258 [==============================] - 49s 191ms/step - loss: 0.5874 - binary_accuracy: 0.6951 - precision_1: 0.6951 - recall_1: 0.6951 - val_loss: 0.5118 - val_binary_accuracy: 0.7188 - val_precision_1: 0.7188 - val_recall_1: 0.7188\n",
            "Epoch 5/60\n",
            "32/32 [==============================] - 0s 1ms/sample - loss: 0.4836 - binary_accuracy: 0.7500 - precision_1: 0.7500 - recall_1: 0.7500\n",
            "258/258 [==============================] - 48s 187ms/step - loss: 0.5772 - binary_accuracy: 0.7075 - precision_1: 0.7075 - recall_1: 0.7075 - val_loss: 0.4836 - val_binary_accuracy: 0.7500 - val_precision_1: 0.7500 - val_recall_1: 0.7500\n",
            "Epoch 6/60\n",
            "32/32 [==============================] - 0s 1ms/sample - loss: 0.5063 - binary_accuracy: 0.7812 - precision_1: 0.7812 - recall_1: 0.7812\n",
            "258/258 [==============================] - 48s 185ms/step - loss: 0.5736 - binary_accuracy: 0.7038 - precision_1: 0.7038 - recall_1: 0.7038 - val_loss: 0.5063 - val_binary_accuracy: 0.7812 - val_precision_1: 0.7812 - val_recall_1: 0.7812\n",
            "Epoch 7/60\n",
            "32/32 [==============================] - 0s 1ms/sample - loss: 0.5509 - binary_accuracy: 0.6562 - precision_1: 0.6562 - recall_1: 0.6562\n",
            "258/258 [==============================] - 48s 185ms/step - loss: 0.5642 - binary_accuracy: 0.7090 - precision_1: 0.7090 - recall_1: 0.7090 - val_loss: 0.5509 - val_binary_accuracy: 0.6562 - val_precision_1: 0.6562 - val_recall_1: 0.6562\n",
            "Epoch 8/60\n",
            "32/32 [==============================] - 0s 1ms/sample - loss: 0.4741 - binary_accuracy: 0.8438 - precision_1: 0.8438 - recall_1: 0.8438\n",
            "258/258 [==============================] - 48s 185ms/step - loss: 0.5665 - binary_accuracy: 0.7171 - precision_1: 0.7171 - recall_1: 0.7171 - val_loss: 0.4741 - val_binary_accuracy: 0.8438 - val_precision_1: 0.8438 - val_recall_1: 0.8438\n",
            "Epoch 9/60\n",
            "32/32 [==============================] - 0s 1ms/sample - loss: 0.5837 - binary_accuracy: 0.7500 - precision_1: 0.7500 - recall_1: 0.7500\n",
            "258/258 [==============================] - 47s 183ms/step - loss: 0.5623 - binary_accuracy: 0.7117 - precision_1: 0.7117 - recall_1: 0.7117 - val_loss: 0.5837 - val_binary_accuracy: 0.7500 - val_precision_1: 0.7500 - val_recall_1: 0.7500\n",
            "Epoch 10/60\n",
            "32/32 [==============================] - 0s 1ms/sample - loss: 0.5110 - binary_accuracy: 0.8125 - precision_1: 0.8125 - recall_1: 0.8125\n",
            "258/258 [==============================] - 48s 186ms/step - loss: 0.5616 - binary_accuracy: 0.7140 - precision_1: 0.7140 - recall_1: 0.7140 - val_loss: 0.5110 - val_binary_accuracy: 0.8125 - val_precision_1: 0.8125 - val_recall_1: 0.8125\n",
            "Epoch 11/60\n",
            "32/32 [==============================] - 0s 1ms/sample - loss: 0.5768 - binary_accuracy: 0.7500 - precision_1: 0.7500 - recall_1: 0.7500\n",
            "258/258 [==============================] - 49s 188ms/step - loss: 0.5693 - binary_accuracy: 0.7084 - precision_1: 0.7084 - recall_1: 0.7084 - val_loss: 0.5768 - val_binary_accuracy: 0.7500 - val_precision_1: 0.7500 - val_recall_1: 0.7500\n",
            "Epoch 12/60\n",
            "32/32 [==============================] - 0s 1ms/sample - loss: 0.5052 - binary_accuracy: 0.8438 - precision_1: 0.8438 - recall_1: 0.8438\n",
            "258/258 [==============================] - 48s 185ms/step - loss: 0.5538 - binary_accuracy: 0.7145 - precision_1: 0.7145 - recall_1: 0.7145 - val_loss: 0.5052 - val_binary_accuracy: 0.8438 - val_precision_1: 0.8438 - val_recall_1: 0.8438\n",
            "Epoch 13/60\n",
            "32/32 [==============================] - 0s 1ms/sample - loss: 0.5197 - binary_accuracy: 0.8125 - precision_1: 0.8125 - recall_1: 0.8125\n",
            "258/258 [==============================] - 48s 185ms/step - loss: 0.5516 - binary_accuracy: 0.7189 - precision_1: 0.7189 - recall_1: 0.7189 - val_loss: 0.5197 - val_binary_accuracy: 0.8125 - val_precision_1: 0.8125 - val_recall_1: 0.8125\n",
            "Epoch 14/60\n",
            "32/32 [==============================] - 0s 2ms/sample - loss: 0.5589 - binary_accuracy: 0.7812 - precision_1: 0.7812 - recall_1: 0.7812\n",
            "258/258 [==============================] - 48s 185ms/step - loss: 0.5426 - binary_accuracy: 0.7243 - precision_1: 0.7243 - recall_1: 0.7243 - val_loss: 0.5589 - val_binary_accuracy: 0.7812 - val_precision_1: 0.7812 - val_recall_1: 0.7812\n",
            "Epoch 15/60\n",
            "32/32 [==============================] - 0s 1ms/sample - loss: 0.5084 - binary_accuracy: 0.8125 - precision_1: 0.8125 - recall_1: 0.8125\n",
            "258/258 [==============================] - 48s 185ms/step - loss: 0.5510 - binary_accuracy: 0.7191 - precision_1: 0.7191 - recall_1: 0.7191 - val_loss: 0.5084 - val_binary_accuracy: 0.8125 - val_precision_1: 0.8125 - val_recall_1: 0.8125\n",
            "Epoch 16/60\n",
            "32/32 [==============================] - 0s 2ms/sample - loss: 0.6174 - binary_accuracy: 0.7188 - precision_1: 0.7188 - recall_1: 0.7188\n",
            "258/258 [==============================] - 47s 183ms/step - loss: 0.5549 - binary_accuracy: 0.7172 - precision_1: 0.7172 - recall_1: 0.7172 - val_loss: 0.6174 - val_binary_accuracy: 0.7188 - val_precision_1: 0.7188 - val_recall_1: 0.7188\n",
            "Epoch 17/60\n",
            "32/32 [==============================] - 0s 1ms/sample - loss: 0.5803 - binary_accuracy: 0.8125 - precision_1: 0.8125 - recall_1: 0.8125\n",
            "258/258 [==============================] - 48s 186ms/step - loss: 0.5425 - binary_accuracy: 0.7238 - precision_1: 0.7238 - recall_1: 0.7238 - val_loss: 0.5803 - val_binary_accuracy: 0.8125 - val_precision_1: 0.8125 - val_recall_1: 0.8125\n",
            "Epoch 18/60\n",
            "32/32 [==============================] - 0s 1ms/sample - loss: 0.5330 - binary_accuracy: 0.8125 - precision_1: 0.8125 - recall_1: 0.8125\n",
            "258/258 [==============================] - 48s 187ms/step - loss: 0.5440 - binary_accuracy: 0.7230 - precision_1: 0.7230 - recall_1: 0.7230 - val_loss: 0.5330 - val_binary_accuracy: 0.8125 - val_precision_1: 0.8125 - val_recall_1: 0.8125\n",
            "Epoch 19/60\n",
            "32/32 [==============================] - 0s 1ms/sample - loss: 0.6096 - binary_accuracy: 0.8125 - precision_1: 0.8125 - recall_1: 0.8125\n",
            "258/258 [==============================] - 48s 185ms/step - loss: 0.5352 - binary_accuracy: 0.7342 - precision_1: 0.7342 - recall_1: 0.7342 - val_loss: 0.6096 - val_binary_accuracy: 0.8125 - val_precision_1: 0.8125 - val_recall_1: 0.8125\n",
            "Epoch 20/60\n",
            "32/32 [==============================] - 0s 1ms/sample - loss: 0.5571 - binary_accuracy: 0.7812 - precision_1: 0.7812 - recall_1: 0.7812\n",
            "258/258 [==============================] - 48s 187ms/step - loss: 0.5299 - binary_accuracy: 0.7334 - precision_1: 0.7334 - recall_1: 0.7334 - val_loss: 0.5571 - val_binary_accuracy: 0.7812 - val_precision_1: 0.7812 - val_recall_1: 0.7812\n",
            "Epoch 21/60\n",
            "32/32 [==============================] - 0s 1ms/sample - loss: 0.5054 - binary_accuracy: 0.8125 - precision_1: 0.8125 - recall_1: 0.8125\n",
            "258/258 [==============================] - 47s 184ms/step - loss: 0.5421 - binary_accuracy: 0.7265 - precision_1: 0.7265 - recall_1: 0.7265 - val_loss: 0.5054 - val_binary_accuracy: 0.8125 - val_precision_1: 0.8125 - val_recall_1: 0.8125\n",
            "Epoch 22/60\n",
            "32/32 [==============================] - 0s 2ms/sample - loss: 0.5206 - binary_accuracy: 0.8125 - precision_1: 0.8125 - recall_1: 0.8125\n",
            "258/258 [==============================] - 48s 186ms/step - loss: 0.5292 - binary_accuracy: 0.7323 - precision_1: 0.7323 - recall_1: 0.7323 - val_loss: 0.5206 - val_binary_accuracy: 0.8125 - val_precision_1: 0.8125 - val_recall_1: 0.8125\n",
            "Epoch 23/60\n",
            "32/32 [==============================] - 0s 1ms/sample - loss: 0.5525 - binary_accuracy: 0.7812 - precision_1: 0.7812 - recall_1: 0.7812\n",
            "258/258 [==============================] - 49s 192ms/step - loss: 0.5333 - binary_accuracy: 0.7282 - precision_1: 0.7282 - recall_1: 0.7282 - val_loss: 0.5525 - val_binary_accuracy: 0.7812 - val_precision_1: 0.7812 - val_recall_1: 0.7812\n",
            "Epoch 24/60\n",
            "32/32 [==============================] - 0s 1ms/sample - loss: 0.5046 - binary_accuracy: 0.7812 - precision_1: 0.7812 - recall_1: 0.7812\n",
            "258/258 [==============================] - 48s 187ms/step - loss: 0.5253 - binary_accuracy: 0.7402 - precision_1: 0.7402 - recall_1: 0.7402 - val_loss: 0.5046 - val_binary_accuracy: 0.7812 - val_precision_1: 0.7812 - val_recall_1: 0.7812\n",
            "Epoch 25/60\n",
            "32/32 [==============================] - 0s 1ms/sample - loss: 0.4297 - binary_accuracy: 0.7812 - precision_1: 0.7812 - recall_1: 0.7812\n",
            "258/258 [==============================] - 47s 184ms/step - loss: 0.5325 - binary_accuracy: 0.7330 - precision_1: 0.7330 - recall_1: 0.7330 - val_loss: 0.4297 - val_binary_accuracy: 0.7812 - val_precision_1: 0.7812 - val_recall_1: 0.7812\n",
            "Epoch 26/60\n",
            "32/32 [==============================] - 0s 1ms/sample - loss: 0.5000 - binary_accuracy: 0.7500 - precision_1: 0.7500 - recall_1: 0.7500\n",
            "258/258 [==============================] - 47s 183ms/step - loss: 0.5403 - binary_accuracy: 0.7272 - precision_1: 0.7272 - recall_1: 0.7272 - val_loss: 0.5000 - val_binary_accuracy: 0.7500 - val_precision_1: 0.7500 - val_recall_1: 0.7500\n",
            "Epoch 27/60\n",
            "32/32 [==============================] - 0s 1ms/sample - loss: 0.5265 - binary_accuracy: 0.7812 - precision_1: 0.7812 - recall_1: 0.7812\n",
            "258/258 [==============================] - 48s 184ms/step - loss: 0.5196 - binary_accuracy: 0.7385 - precision_1: 0.7385 - recall_1: 0.7385 - val_loss: 0.5265 - val_binary_accuracy: 0.7812 - val_precision_1: 0.7812 - val_recall_1: 0.7812\n",
            "Epoch 28/60\n",
            "32/32 [==============================] - 0s 1ms/sample - loss: 0.4985 - binary_accuracy: 0.6875 - precision_1: 0.6875 - recall_1: 0.6875\n",
            "258/258 [==============================] - 47s 184ms/step - loss: 0.5169 - binary_accuracy: 0.7344 - precision_1: 0.7344 - recall_1: 0.7344 - val_loss: 0.4985 - val_binary_accuracy: 0.6875 - val_precision_1: 0.6875 - val_recall_1: 0.6875\n",
            "Epoch 29/60\n",
            "32/32 [==============================] - 0s 1ms/sample - loss: 0.4862 - binary_accuracy: 0.7812 - precision_1: 0.7812 - recall_1: 0.7812\n",
            "258/258 [==============================] - 47s 184ms/step - loss: 0.5262 - binary_accuracy: 0.7361 - precision_1: 0.7361 - recall_1: 0.7361 - val_loss: 0.4862 - val_binary_accuracy: 0.7812 - val_precision_1: 0.7812 - val_recall_1: 0.7812\n",
            "Epoch 30/60\n",
            "32/32 [==============================] - 0s 1ms/sample - loss: 0.5235 - binary_accuracy: 0.7812 - precision_1: 0.7812 - recall_1: 0.7812\n",
            "258/258 [==============================] - 48s 187ms/step - loss: 0.5254 - binary_accuracy: 0.7377 - precision_1: 0.7377 - recall_1: 0.7377 - val_loss: 0.5235 - val_binary_accuracy: 0.7812 - val_precision_1: 0.7812 - val_recall_1: 0.7812\n",
            "Epoch 31/60\n",
            "32/32 [==============================] - 0s 2ms/sample - loss: 0.5321 - binary_accuracy: 0.7188 - precision_1: 0.7188 - recall_1: 0.7188\n",
            "258/258 [==============================] - 47s 183ms/step - loss: 0.5172 - binary_accuracy: 0.7382 - precision_1: 0.7382 - recall_1: 0.7382 - val_loss: 0.5321 - val_binary_accuracy: 0.7188 - val_precision_1: 0.7188 - val_recall_1: 0.7188\n",
            "Epoch 32/60\n",
            "32/32 [==============================] - 0s 1ms/sample - loss: 0.5097 - binary_accuracy: 0.7812 - precision_1: 0.7812 - recall_1: 0.7812\n",
            "258/258 [==============================] - 48s 184ms/step - loss: 0.5246 - binary_accuracy: 0.7356 - precision_1: 0.7356 - recall_1: 0.7356 - val_loss: 0.5097 - val_binary_accuracy: 0.7812 - val_precision_1: 0.7812 - val_recall_1: 0.7812\n",
            "Epoch 33/60\n",
            "32/32 [==============================] - 0s 1ms/sample - loss: 0.5016 - binary_accuracy: 0.7812 - precision_1: 0.7812 - recall_1: 0.7812\n",
            "258/258 [==============================] - 47s 184ms/step - loss: 0.5244 - binary_accuracy: 0.7404 - precision_1: 0.7404 - recall_1: 0.7404 - val_loss: 0.5016 - val_binary_accuracy: 0.7812 - val_precision_1: 0.7812 - val_recall_1: 0.7812\n",
            "Epoch 34/60\n",
            "32/32 [==============================] - 0s 2ms/sample - loss: 0.5290 - binary_accuracy: 0.7812 - precision_1: 0.7812 - recall_1: 0.7812\n",
            "258/258 [==============================] - 48s 184ms/step - loss: 0.5106 - binary_accuracy: 0.7404 - precision_1: 0.7404 - recall_1: 0.7404 - val_loss: 0.5290 - val_binary_accuracy: 0.7812 - val_precision_1: 0.7812 - val_recall_1: 0.7812\n",
            "Epoch 35/60\n",
            "32/32 [==============================] - 0s 2ms/sample - loss: 0.5213 - binary_accuracy: 0.7500 - precision_1: 0.7500 - recall_1: 0.7500\n",
            "258/258 [==============================] - 48s 185ms/step - loss: 0.5202 - binary_accuracy: 0.7441 - precision_1: 0.7441 - recall_1: 0.7441 - val_loss: 0.5213 - val_binary_accuracy: 0.7500 - val_precision_1: 0.7500 - val_recall_1: 0.7500\n",
            "Epoch 36/60\n",
            "32/32 [==============================] - 0s 2ms/sample - loss: 0.4752 - binary_accuracy: 0.8438 - precision_1: 0.8438 - recall_1: 0.8438\n",
            "258/258 [==============================] - 48s 186ms/step - loss: 0.5148 - binary_accuracy: 0.7455 - precision_1: 0.7455 - recall_1: 0.7455 - val_loss: 0.4752 - val_binary_accuracy: 0.8438 - val_precision_1: 0.8438 - val_recall_1: 0.8438\n",
            "Epoch 37/60\n",
            "32/32 [==============================] - 0s 1ms/sample - loss: 0.5112 - binary_accuracy: 0.8125 - precision_1: 0.8125 - recall_1: 0.8125\n",
            "258/258 [==============================] - 48s 187ms/step - loss: 0.5109 - binary_accuracy: 0.7466 - precision_1: 0.7466 - recall_1: 0.7466 - val_loss: 0.5112 - val_binary_accuracy: 0.8125 - val_precision_1: 0.8125 - val_recall_1: 0.8125\n",
            "Epoch 38/60\n",
            "32/32 [==============================] - 0s 1ms/sample - loss: 0.5175 - binary_accuracy: 0.6875 - precision_1: 0.6875 - recall_1: 0.6875\n",
            "258/258 [==============================] - 47s 184ms/step - loss: 0.5139 - binary_accuracy: 0.7387 - precision_1: 0.7387 - recall_1: 0.7387 - val_loss: 0.5175 - val_binary_accuracy: 0.6875 - val_precision_1: 0.6875 - val_recall_1: 0.6875\n",
            "Epoch 39/60\n",
            "32/32 [==============================] - 0s 1ms/sample - loss: 0.4905 - binary_accuracy: 0.7500 - precision_1: 0.7500 - recall_1: 0.7500\n",
            "258/258 [==============================] - 48s 185ms/step - loss: 0.5052 - binary_accuracy: 0.7424 - precision_1: 0.7424 - recall_1: 0.7424 - val_loss: 0.4905 - val_binary_accuracy: 0.7500 - val_precision_1: 0.7500 - val_recall_1: 0.7500\n",
            "Epoch 40/60\n",
            "32/32 [==============================] - 0s 1ms/sample - loss: 0.4989 - binary_accuracy: 0.8125 - precision_1: 0.8125 - recall_1: 0.8125\n",
            "258/258 [==============================] - 47s 184ms/step - loss: 0.5101 - binary_accuracy: 0.7432 - precision_1: 0.7432 - recall_1: 0.7432 - val_loss: 0.4989 - val_binary_accuracy: 0.8125 - val_precision_1: 0.8125 - val_recall_1: 0.8125\n",
            "Epoch 41/60\n",
            "32/32 [==============================] - 0s 1ms/sample - loss: 0.5485 - binary_accuracy: 0.7812 - precision_1: 0.7812 - recall_1: 0.7812\n",
            "258/258 [==============================] - 47s 184ms/step - loss: 0.5108 - binary_accuracy: 0.7442 - precision_1: 0.7442 - recall_1: 0.7442 - val_loss: 0.5485 - val_binary_accuracy: 0.7812 - val_precision_1: 0.7812 - val_recall_1: 0.7812\n",
            "Epoch 42/60\n",
            "32/32 [==============================] - 0s 1ms/sample - loss: 0.5603 - binary_accuracy: 0.6875 - precision_1: 0.6875 - recall_1: 0.6875\n",
            "258/258 [==============================] - 48s 185ms/step - loss: 0.5025 - binary_accuracy: 0.7505 - precision_1: 0.7505 - recall_1: 0.7505 - val_loss: 0.5603 - val_binary_accuracy: 0.6875 - val_precision_1: 0.6875 - val_recall_1: 0.6875\n",
            "Epoch 43/60\n",
            "32/32 [==============================] - 0s 2ms/sample - loss: 0.6206 - binary_accuracy: 0.6875 - precision_1: 0.6875 - recall_1: 0.6875\n",
            "258/258 [==============================] - 48s 188ms/step - loss: 0.5061 - binary_accuracy: 0.7445 - precision_1: 0.7445 - recall_1: 0.7445 - val_loss: 0.6206 - val_binary_accuracy: 0.6875 - val_precision_1: 0.6875 - val_recall_1: 0.6875\n",
            "Epoch 44/60\n",
            "32/32 [==============================] - 0s 1ms/sample - loss: 0.5478 - binary_accuracy: 0.8125 - precision_1: 0.8125 - recall_1: 0.8125\n",
            "258/258 [==============================] - 48s 185ms/step - loss: 0.5002 - binary_accuracy: 0.7494 - precision_1: 0.7494 - recall_1: 0.7494 - val_loss: 0.5478 - val_binary_accuracy: 0.8125 - val_precision_1: 0.8125 - val_recall_1: 0.8125\n",
            "Epoch 45/60\n",
            "32/32 [==============================] - 0s 2ms/sample - loss: 0.5185 - binary_accuracy: 0.7812 - precision_1: 0.7812 - recall_1: 0.7812\n",
            "258/258 [==============================] - 48s 185ms/step - loss: 0.5111 - binary_accuracy: 0.7444 - precision_1: 0.7444 - recall_1: 0.7444 - val_loss: 0.5185 - val_binary_accuracy: 0.7812 - val_precision_1: 0.7812 - val_recall_1: 0.7812\n",
            "Epoch 46/60\n",
            "32/32 [==============================] - 0s 1ms/sample - loss: 0.6390 - binary_accuracy: 0.8125 - precision_1: 0.8125 - recall_1: 0.8125\n",
            "258/258 [==============================] - 48s 185ms/step - loss: 0.5044 - binary_accuracy: 0.7473 - precision_1: 0.7473 - recall_1: 0.7473 - val_loss: 0.6390 - val_binary_accuracy: 0.8125 - val_precision_1: 0.8125 - val_recall_1: 0.8125\n",
            "Epoch 47/60\n",
            "32/32 [==============================] - 0s 1ms/sample - loss: 0.6713 - binary_accuracy: 0.8125 - precision_1: 0.8125 - recall_1: 0.8125\n",
            "258/258 [==============================] - 47s 184ms/step - loss: 0.5081 - binary_accuracy: 0.7468 - precision_1: 0.7468 - recall_1: 0.7468 - val_loss: 0.6713 - val_binary_accuracy: 0.8125 - val_precision_1: 0.8125 - val_recall_1: 0.8125\n",
            "Epoch 48/60\n",
            "32/32 [==============================] - 0s 1ms/sample - loss: 0.5309 - binary_accuracy: 0.8438 - precision_1: 0.8438 - recall_1: 0.8438\n",
            "258/258 [==============================] - 48s 184ms/step - loss: 0.5104 - binary_accuracy: 0.7385 - precision_1: 0.7385 - recall_1: 0.7385 - val_loss: 0.5309 - val_binary_accuracy: 0.8438 - val_precision_1: 0.8438 - val_recall_1: 0.8438\n",
            "Epoch 49/60\n",
            "32/32 [==============================] - 0s 1ms/sample - loss: 0.5340 - binary_accuracy: 0.8125 - precision_1: 0.8125 - recall_1: 0.8125\n",
            "258/258 [==============================] - 48s 187ms/step - loss: 0.5055 - binary_accuracy: 0.7478 - precision_1: 0.7478 - recall_1: 0.7478 - val_loss: 0.5340 - val_binary_accuracy: 0.8125 - val_precision_1: 0.8125 - val_recall_1: 0.8125\n",
            "Epoch 50/60\n",
            "32/32 [==============================] - 0s 1ms/sample - loss: 0.6296 - binary_accuracy: 0.7188 - precision_1: 0.7188 - recall_1: 0.7188\n",
            "258/258 [==============================] - 49s 189ms/step - loss: 0.5049 - binary_accuracy: 0.7532 - precision_1: 0.7532 - recall_1: 0.7532 - val_loss: 0.6296 - val_binary_accuracy: 0.7188 - val_precision_1: 0.7188 - val_recall_1: 0.7188\n",
            "Epoch 51/60\n",
            "32/32 [==============================] - 0s 1ms/sample - loss: 0.6667 - binary_accuracy: 0.7812 - precision_1: 0.7812 - recall_1: 0.7812\n",
            "258/258 [==============================] - 48s 185ms/step - loss: 0.4986 - binary_accuracy: 0.7498 - precision_1: 0.7498 - recall_1: 0.7498 - val_loss: 0.6667 - val_binary_accuracy: 0.7812 - val_precision_1: 0.7812 - val_recall_1: 0.7812\n",
            "Epoch 52/60\n",
            "32/32 [==============================] - 0s 1ms/sample - loss: 0.6021 - binary_accuracy: 0.7188 - precision_1: 0.7188 - recall_1: 0.7188\n",
            "258/258 [==============================] - 48s 185ms/step - loss: 0.4971 - binary_accuracy: 0.7535 - precision_1: 0.7535 - recall_1: 0.7535 - val_loss: 0.6021 - val_binary_accuracy: 0.7188 - val_precision_1: 0.7188 - val_recall_1: 0.7188\n",
            "Epoch 53/60\n",
            "32/32 [==============================] - 0s 1ms/sample - loss: 0.6037 - binary_accuracy: 0.8125 - precision_1: 0.8125 - recall_1: 0.8125\n",
            "258/258 [==============================] - 48s 185ms/step - loss: 0.4946 - binary_accuracy: 0.7557 - precision_1: 0.7557 - recall_1: 0.7557 - val_loss: 0.6037 - val_binary_accuracy: 0.8125 - val_precision_1: 0.8125 - val_recall_1: 0.8125\n",
            "Epoch 54/60\n",
            "32/32 [==============================] - 0s 2ms/sample - loss: 0.5836 - binary_accuracy: 0.7812 - precision_1: 0.7812 - recall_1: 0.7812\n",
            "258/258 [==============================] - 48s 186ms/step - loss: 0.4963 - binary_accuracy: 0.7524 - precision_1: 0.7524 - recall_1: 0.7524 - val_loss: 0.5836 - val_binary_accuracy: 0.7812 - val_precision_1: 0.7812 - val_recall_1: 0.7812\n",
            "Epoch 55/60\n",
            "32/32 [==============================] - 0s 1ms/sample - loss: 0.6824 - binary_accuracy: 0.8438 - precision_1: 0.8438 - recall_1: 0.8438\n",
            "258/258 [==============================] - 48s 187ms/step - loss: 0.5015 - binary_accuracy: 0.7484 - precision_1: 0.7484 - recall_1: 0.7484 - val_loss: 0.6824 - val_binary_accuracy: 0.8438 - val_precision_1: 0.8438 - val_recall_1: 0.8438\n",
            "Epoch 56/60\n",
            "32/32 [==============================] - 0s 1ms/sample - loss: 0.5653 - binary_accuracy: 0.7812 - precision_1: 0.7812 - recall_1: 0.7812\n",
            "258/258 [==============================] - 49s 188ms/step - loss: 0.4992 - binary_accuracy: 0.7482 - precision_1: 0.7482 - recall_1: 0.7482 - val_loss: 0.5653 - val_binary_accuracy: 0.7812 - val_precision_1: 0.7812 - val_recall_1: 0.7812\n",
            "Epoch 57/60\n",
            "32/32 [==============================] - 0s 1ms/sample - loss: 0.5634 - binary_accuracy: 0.7812 - precision_1: 0.7812 - recall_1: 0.7812\n",
            "258/258 [==============================] - 48s 185ms/step - loss: 0.4922 - binary_accuracy: 0.7562 - precision_1: 0.7562 - recall_1: 0.7562 - val_loss: 0.5634 - val_binary_accuracy: 0.7812 - val_precision_1: 0.7812 - val_recall_1: 0.7812\n",
            "Epoch 58/60\n",
            "32/32 [==============================] - 0s 2ms/sample - loss: 0.5787 - binary_accuracy: 0.7188 - precision_1: 0.7188 - recall_1: 0.7188\n",
            "258/258 [==============================] - 48s 184ms/step - loss: 0.5033 - binary_accuracy: 0.7529 - precision_1: 0.7529 - recall_1: 0.7529 - val_loss: 0.5787 - val_binary_accuracy: 0.7188 - val_precision_1: 0.7188 - val_recall_1: 0.7188\n",
            "Epoch 59/60\n",
            "32/32 [==============================] - 0s 1ms/sample - loss: 0.5681 - binary_accuracy: 0.7812 - precision_1: 0.7812 - recall_1: 0.7812\n",
            "258/258 [==============================] - 48s 185ms/step - loss: 0.4894 - binary_accuracy: 0.7576 - precision_1: 0.7576 - recall_1: 0.7576 - val_loss: 0.5681 - val_binary_accuracy: 0.7812 - val_precision_1: 0.7812 - val_recall_1: 0.7812\n",
            "Epoch 60/60\n",
            "32/32 [==============================] - 0s 1ms/sample - loss: 0.5455 - binary_accuracy: 0.7812 - precision_1: 0.7812 - recall_1: 0.7812\n",
            "258/258 [==============================] - 48s 185ms/step - loss: 0.4930 - binary_accuracy: 0.7566 - precision_1: 0.7566 - recall_1: 0.7566 - val_loss: 0.5455 - val_binary_accuracy: 0.7812 - val_precision_1: 0.7812 - val_recall_1: 0.7812\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f55b1bcbf60>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2OXLqlez8Xn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = naive_model() # keras_model()\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.train.AdamOptimizer(), \n",
        "    loss=tf.keras.losses.binary_crossentropy,\n",
        "    metrics=['accuracy', 'binary_crossentropy']) # tf.keras.metrics.Precision(), tf.keras.metrics.Recall(), \n",
        "\n",
        "\n",
        "model.fit(\n",
        "    overfit_batch[0],\n",
        "    overfit_batch[1],\n",
        "    steps_per_epoch=len(overfit_batch[0]) // batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=validate_batch,\n",
        "    validation_steps=1,\n",
        "    verbose = 1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9bmvgEaxy_o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "\n",
        "\n",
        "from pathlib import Path\n",
        "import random\n",
        "\n",
        "def dataset(data_root, batch_size, verbose=False, autotune=tf.data.experimental.AUTOTUNE):\n",
        "    all_image_paths, label_names = dir_to_paths_and_labels(data_root)\n",
        "    unbatched_ds = unbatched_dataset(all_image_paths, label_names, verbose=verbose)\n",
        "\n",
        "    ds = unbatched_ds.apply(tf.data.experimental.shuffle_and_repeat(buffer_size=len(all_image_paths)))\n",
        "    ds = ds.batch(batch_size)\n",
        "    ds = ds.prefetch(buffer_size=autotune)\n",
        "    return ds, label_names, all_image_paths\n",
        "\n",
        "def all_dataset(data_root, verbose=False):\n",
        "    all_image_paths, label_names = dir_to_paths_and_labels(data_root)\n",
        "    unbatched_ds = unbatched_dataset(all_image_paths, label_names, verbose=verbose)\n",
        "    return unbatched_ds, label_names, all_image_paths\n",
        "\n",
        "def unbatched_dataset(all_image_paths, label_names, verbose=False, limit=None):\n",
        "    label_to_index = dict((name, index) for index,name in enumerate(label_names))\n",
        "    all_image_labels = [label_to_index[Path(path).parent.name] for path in all_image_paths]\n",
        "\n",
        "    verbose_size = 10\n",
        "    if (limit):\n",
        "      all_image_paths  = all_image_paths[:limit]\n",
        "      all_image_labels = all_image_labels[:limit]\n",
        "      verbose_size = limit\n",
        "\n",
        "    if verbose:\n",
        "        print(\"label to index map \", label_to_index)\n",
        "        print(f\"First {verbose_size} labels indices: {all_image_labels[:verbose_size]}\")\n",
        "        print(f\"First {verbose_size} paths indices: {all_image_paths[:verbose_size]}\")\n",
        "\n",
        "    ds = tf.data.Dataset.from_tensor_slices((all_image_paths, all_image_labels))      \n",
        "    image_label_ds = ds.map(load_and_preprocess_from_path_label)\n",
        "    return image_label_ds\n",
        "\n",
        "def dir_to_paths_and_labels(data_root):\n",
        "    all_image_paths = dir_to_files(data_root)\n",
        "    label_names = sorted(item.name for item in data_root.glob('*/') if item.is_dir())\n",
        "    return all_image_paths, label_names\n",
        "\n",
        "def dir_to_files(data_root):\n",
        "    all_image_paths = list(data_root.glob('*/*'))\n",
        "    all_image_paths = [str(path) for path in all_image_paths if path.suffix != '']\n",
        "    random.shuffle(all_image_paths)\n",
        "    return all_image_paths\n",
        "\n",
        "#\n",
        "# If imagenet weights are being loaded, input must have a static square \n",
        "#    shape(one of (96, 96), (128, 128), (160, 160),(192, 192), or (224, 224)\n",
        "def preprocess_image(image, sizes=(64, 3)):\n",
        "  image = tf.image.decode_jpeg(image, channels=sizes[1])\n",
        "  image = tf.image.resize_images(image, [sizes[0], sizes[0]])\n",
        "  image /= 255.0  # normalize to [0,1] range\n",
        "  image = tf.reshape(image, (1, sizes[0], sizes[0], sizes[1]))\n",
        "  return image\n",
        "\n",
        "def load_and_preprocess_image(path):\n",
        "  print(f\"{path}\")\n",
        "  image = tf.read_file(path)\n",
        "  return preprocess_image(image)\n",
        "\n",
        "def load_and_preprocess_from_path_label(path, label):\n",
        "  return load_and_preprocess_image(path), tf.one_hot(tf.cast(label, tf.uint8), 2) # label # "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucU0s2ZdSmfS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout, Input, BatchNormalization\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.python.keras.applications import ResNet50\n",
        "\n",
        "def naive_model(input_shape=(64, 64, 3), hidden=12288, num_classes=2):\n",
        "  model = Sequential()\n",
        "  model.add(Dense(hidden, activation=None))\n",
        "#  model.add(Dense(4, activation=tf.nn.relu))\n",
        "  model.add(Dense(num_classes, activation=tf.nn.sigmoid))\n",
        "  return model\n",
        "\n",
        "\n",
        "def resnet50_model(num_classes=2):\n",
        "  model = Sequential()\n",
        "  #keras.applications.resnet.ResNet50(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000)\n",
        "  model.add(ResNet50(include_top=False, pooling='avg', weights='imagenet'))\n",
        "  model.add(Flatten())\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dense(2048, activation='relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dense(1024, activation='relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dense(num_classes, activation='softmax'))\n",
        "  model.layers[0].trainable = False\n",
        "  return model\n",
        "\n",
        "\n",
        "def keras_model(input_shape=(64, 64, 3), num_classes=2):\n",
        "    model = Sequential()\n",
        "    if len(input_shape) < 3:\n",
        "        model.add(Lambda(lambda x: tf.expand_dims(x, -1), input_shape=input_shape))\n",
        "        input_shape = (input_shape[0], input_shape[1], 1)\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', padding='valid', input_shape=input_shape))\n",
        "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "#    model.add(Dropout(0.2))\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(512, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "    return model\n",
        "#     inputs = Input(shape=input_shape)\n",
        "#     x = Conv2D(32, (3, 3),activation='relu', padding='valid')(inputs)\n",
        "#     x = MaxPool2D(pool_size=(2, 2))(x)\n",
        "#     x = Conv2D(64, (3, 3), activation='relu')(x)\n",
        "#     x = MaxPool2D(pool_size=(2, 2))(x)\n",
        "#     x = Flatten()(x)\n",
        "#     x = Dense(512, activation='relu')(x)\n",
        "#     x = Dropout(0.5)(x)\n",
        "#     outputs = Dense(num_classes, activation='softmax')(x)    \n",
        "#     return tf.keras.Model(inputs, outputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YX2tj76vXLeu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import IPython.display as display\n",
        "\n",
        "def caption_image(image_path):\n",
        "    image_rel = Path(image_path).relative_to(data_root)\n",
        "    return \"Image \" + str(image_rel)\n",
        "  \n",
        "for n in range(10):\n",
        "  image_path = random.choice(all_image_paths)\n",
        "  display.display(display.Image(image_path))\n",
        "  print(caption_image(image_path))\n",
        "  print()\n",
        "\n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muc49zn6m4uO",
        "colab_type": "code",
        "outputId": "e21e1d36-b256-4cde-c38d-632fb378f2db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.enable_eager_execution()\n",
        "print(f\"Tensorflow version: {tf.__version__}\")\n",
        "\n",
        "if tf.test.is_gpu_available():\n",
        "  print('Using GPU')\n",
        "else:\n",
        "  print('Not using GPU')\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow version: 1.13.1\n",
            "Using GPU\n",
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}